{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3rd_homework_Meszaros_Balint.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJy9zvvk5ke/wb18k920+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mebalint/3rd_homework/blob/main/3rd_homework_Meszaros_Balint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOkSTrguLzIv"
      },
      "source": [
        "\n",
        "Deep Learning 3rd homework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI4_4DK3pqVH"
      },
      "source": [
        "# importing packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BqLkM6Yp2IK"
      },
      "source": [
        "# also importing packages, but for deep learning\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkWH5z9Cp5HV"
      },
      "source": [
        "# reading the data of March 2014 in\n",
        "list_of_dfs = pd.read_html('https://freemeteo.hu/idojaras/budapest/elozmenyek/havi-elozmenyek/?gid=3054643&station=4276&month=3&year=2014&language=hungarian&country=hungary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeJ7_PEmHxBg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2baca9f5-f032-4007-9c65-6618fa4f042a"
      },
      "source": [
        "# printing the data out\n",
        "list_of_dfs[6].iloc[:,0:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dátum</th>\n",
              "      <th>Napi min hőmérséklet</th>\n",
              "      <th>Napi max hőmérséklet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2014.03.01.</td>\n",
              "      <td>0°C</td>\n",
              "      <td>12°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2014.03.02.</td>\n",
              "      <td>4°C</td>\n",
              "      <td>11°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2014.03.03.</td>\n",
              "      <td>4°C</td>\n",
              "      <td>7°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014.03.04.</td>\n",
              "      <td>4°C</td>\n",
              "      <td>10°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014.03.05.</td>\n",
              "      <td>4°C</td>\n",
              "      <td>12°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2014.03.06.</td>\n",
              "      <td>6°C</td>\n",
              "      <td>14°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2014.03.07.</td>\n",
              "      <td>6°C</td>\n",
              "      <td>10°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2014.03.08.</td>\n",
              "      <td>2°C</td>\n",
              "      <td>15°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2014.03.09.</td>\n",
              "      <td>0°C</td>\n",
              "      <td>13°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2014.03.10.</td>\n",
              "      <td>-1°C</td>\n",
              "      <td>12°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2014.03.11.</td>\n",
              "      <td>-3°C</td>\n",
              "      <td>16°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2014.03.12.</td>\n",
              "      <td>-2°C</td>\n",
              "      <td>17°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2014.03.13.</td>\n",
              "      <td>-2°C</td>\n",
              "      <td>17°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2014.03.14.</td>\n",
              "      <td>-2°C</td>\n",
              "      <td>18°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2014.03.15.</td>\n",
              "      <td>-1°C</td>\n",
              "      <td>17°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2014.03.16.</td>\n",
              "      <td>4°C</td>\n",
              "      <td>14°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2014.03.17.</td>\n",
              "      <td>7°C</td>\n",
              "      <td>15°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2014.03.18.</td>\n",
              "      <td>5°C</td>\n",
              "      <td>17°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2014.03.19.</td>\n",
              "      <td>6°C</td>\n",
              "      <td>16°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2014.03.20.</td>\n",
              "      <td>4°C</td>\n",
              "      <td>20°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2014.03.21.</td>\n",
              "      <td>2°C</td>\n",
              "      <td>21°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2014.03.22.</td>\n",
              "      <td>6°C</td>\n",
              "      <td>21°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2014.03.23.</td>\n",
              "      <td>10°C</td>\n",
              "      <td>20°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2014.03.24.</td>\n",
              "      <td>5°C</td>\n",
              "      <td>11°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2014.03.25.</td>\n",
              "      <td>-1°C</td>\n",
              "      <td>11°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2014.03.26.</td>\n",
              "      <td>-2°C</td>\n",
              "      <td>13°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2014.03.27.</td>\n",
              "      <td>4°C</td>\n",
              "      <td>16°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2014.03.28.</td>\n",
              "      <td>5°C</td>\n",
              "      <td>19°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2014.03.29.</td>\n",
              "      <td>4°C</td>\n",
              "      <td>20°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2014.03.30.</td>\n",
              "      <td>0°C</td>\n",
              "      <td>20°C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2014.03.31.</td>\n",
              "      <td>1°C</td>\n",
              "      <td>21°C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Dátum Napi min hőmérséklet Napi max hőmérséklet\n",
              "0   2014.03.01.                  0°C                 12°C\n",
              "1   2014.03.02.                  4°C                 11°C\n",
              "2   2014.03.03.                  4°C                  7°C\n",
              "3   2014.03.04.                  4°C                 10°C\n",
              "4   2014.03.05.                  4°C                 12°C\n",
              "5   2014.03.06.                  6°C                 14°C\n",
              "6   2014.03.07.                  6°C                 10°C\n",
              "7   2014.03.08.                  2°C                 15°C\n",
              "8   2014.03.09.                  0°C                 13°C\n",
              "9   2014.03.10.                 -1°C                 12°C\n",
              "10  2014.03.11.                 -3°C                 16°C\n",
              "11  2014.03.12.                 -2°C                 17°C\n",
              "12  2014.03.13.                 -2°C                 17°C\n",
              "13  2014.03.14.                 -2°C                 18°C\n",
              "14  2014.03.15.                 -1°C                 17°C\n",
              "15  2014.03.16.                  4°C                 14°C\n",
              "16  2014.03.17.                  7°C                 15°C\n",
              "17  2014.03.18.                  5°C                 17°C\n",
              "18  2014.03.19.                  6°C                 16°C\n",
              "19  2014.03.20.                  4°C                 20°C\n",
              "20  2014.03.21.                  2°C                 21°C\n",
              "21  2014.03.22.                  6°C                 21°C\n",
              "22  2014.03.23.                 10°C                 20°C\n",
              "23  2014.03.24.                  5°C                 11°C\n",
              "24  2014.03.25.                 -1°C                 11°C\n",
              "25  2014.03.26.                 -2°C                 13°C\n",
              "26  2014.03.27.                  4°C                 16°C\n",
              "27  2014.03.28.                  5°C                 19°C\n",
              "28  2014.03.29.                  4°C                 20°C\n",
              "29  2014.03.30.                  0°C                 20°C\n",
              "30  2014.03.31.                  1°C                 21°C"
            ]
          },
          "metadata": {},
          "execution_count": 451
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMKiWiv81SDy"
      },
      "source": [
        "# a function for scraping data for a given month and year\n",
        "def scraping(year, month, html1='https://freemeteo.hu/idojaras/budapest/elozmenyek/havi-elozmenyek/?gid=3054643&station=4276&month=', html2='&year=', html3='&language=hungarian&country=hungary'):\n",
        "    list_of_dfs = pd.read_html(html1+str(month)+html2+str(year)+html3)\n",
        "    table=list_of_dfs[6].iloc[:,0:3]\n",
        "    return table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxAEPSbjzrBf"
      },
      "source": [
        "# data is from 2011 to 2020\n",
        "years=range(2011,2021)\n",
        "months=range(1,13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOCilkPc2vCk"
      },
      "source": [
        "# making the dataframes for every year and month\n",
        "dataframes=[]\n",
        "for year in years:\n",
        "  for month in months:\n",
        "    dataframes.append(scraping(year, month))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYyHrOEF3P2H",
        "outputId": "853cac30-d528-452c-fa46-0eadba7f4ffa"
      },
      "source": [
        "# it is not important, i have just checked if every dataframe has a good length\n",
        "# the number of days of the months\n",
        "days=[31,28,31,30,31,30,31,31,30,31,30,31]\n",
        "# checking for every dataframe\n",
        "for j in range(120):\n",
        "  if len(dataframes[j])!=days[j%12]:\n",
        "    print(j)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n",
            "35\n",
            "47\n",
            "59\n",
            "61\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "100\n",
            "107\n",
            "109\n",
            "119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfrFJqLpCSxC"
      },
      "source": [
        "# these deletings are because the data is nan\n",
        "dataframes[10]=dataframes[10].drop(labels=19,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4LVGtSXIMQ9"
      },
      "source": [
        "dataframes[57]=dataframes[57].drop(labels=15,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVyml-D_IYk-"
      },
      "source": [
        "dataframes[62]=dataframes[62].drop(labels=12,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbDK-iGxIjpS"
      },
      "source": [
        "dataframes[107]=dataframes[107].drop(labels=4,axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1Oe3Y3kItXW"
      },
      "source": [
        "dataframes[119]=dataframes[119].drop(labels=[17,18],axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owMNGZpDCDqU"
      },
      "source": [
        "# dataframes for min temperature \n",
        "dfsmin=[]\n",
        "for i in range(120):\n",
        "  # selecting the min column, and transforming it as a float\n",
        "  minim=[float(data[0:-2]) for data in dataframes[i].iloc[:,1].values]\n",
        "  # every 7 succesive temperature determines the 8th temperature in my model\n",
        "  traindata=[minim[i:i+8] for i in range(len(minim)-7)]\n",
        "  df=pd.DataFrame(traindata, columns=['x1','x2','x3','x4','x5','x6','x7','y'])\n",
        "  dfsmin.append(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwNwolstJeU_"
      },
      "source": [
        "# dataframes for max temperature \n",
        "dfsmax=[]\n",
        "for i in range(120):\n",
        "  # selecting the max column, and transforming is as a float\n",
        "  maxim=[float(data[0:-2]) for data in dataframes[i].iloc[:,2].values]\n",
        "  # every 7 succesive temperature determines the 8th temperature in my model\n",
        "  traindata=[maxim[i:i+8] for i in range(len(maxim)-7)]\n",
        "  df=pd.DataFrame(traindata, columns=['x1','x2','x3','x4','x5','x6','x7','y'])\n",
        "  dfsmax.append(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "kRwv2vb4I5Vw",
        "outputId": "0d8ea687-3f25-479a-a475-0d11188a2751"
      },
      "source": [
        "# concatenating the dataframes of min temperatures\n",
        "trainmin=pd.concat(dfsmin)\n",
        "trainmin\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-5.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-5.0</td>\n",
              "      <td>-11.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-11.0</td>\n",
              "      <td>-5.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-5.0</td>\n",
              "      <td>-6.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-6.0</td>\n",
              "      <td>-10.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>-8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2245 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      x1    x2    x3    x4    x5    x6   x7    y\n",
              "0   -5.0  -5.0 -11.0  -5.0  -6.0 -10.0 -1.0 -1.0\n",
              "1   -5.0 -11.0  -5.0  -6.0 -10.0  -1.0 -1.0 -3.0\n",
              "2  -11.0  -5.0  -6.0 -10.0  -1.0  -1.0 -3.0 -2.0\n",
              "3   -5.0  -6.0 -10.0  -1.0  -1.0  -3.0 -2.0  3.0\n",
              "4   -6.0 -10.0  -1.0  -1.0  -3.0  -2.0  3.0  0.0\n",
              "..   ...   ...   ...   ...   ...   ...  ...  ...\n",
              "13   2.0   1.0   3.0   2.0   3.0   3.0  3.0  5.0\n",
              "14   1.0   3.0   2.0   3.0   3.0   3.0  5.0  5.0\n",
              "15   3.0   2.0   3.0   3.0   3.0   5.0  5.0  2.0\n",
              "16   2.0   3.0   3.0   3.0   5.0   5.0  2.0 -4.0\n",
              "17   3.0   3.0   3.0   5.0   5.0   2.0 -4.0 -8.0\n",
              "\n",
              "[2245 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "h83AOJO4JpVH",
        "outputId": "818ba8d4-0e93-4edc-ac3c-43f7cedc8907"
      },
      "source": [
        "# concatenating the dataframes of max temperatures\n",
        "trainmax=pd.concat(dfsmax)\n",
        "trainmax"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-3.0</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2245 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     x1   x2   x3    x4    x5    x6    x7     y\n",
              "0  -2.0  1.0 -1.0  -3.0  -4.0   1.0   3.0   4.0\n",
              "1   1.0 -1.0 -3.0  -4.0   1.0   3.0   4.0   4.0\n",
              "2  -1.0 -3.0 -4.0   1.0   3.0   4.0   4.0   4.0\n",
              "3  -3.0 -4.0  1.0   3.0   4.0   4.0   4.0   5.0\n",
              "4  -4.0  1.0  3.0   4.0   4.0   4.0   5.0   7.0\n",
              "..  ...  ...  ...   ...   ...   ...   ...   ...\n",
              "13  3.0  3.0  4.0   4.0   4.0   5.0   5.0  11.0\n",
              "14  3.0  4.0  4.0   4.0   5.0   5.0  11.0   9.0\n",
              "15  4.0  4.0  4.0   5.0   5.0  11.0   9.0   6.0\n",
              "16  4.0  4.0  5.0   5.0  11.0   9.0   6.0   5.0\n",
              "17  4.0  5.0  5.0  11.0   9.0   6.0   5.0   1.0\n",
              "\n",
              "[2245 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5gPn01l8bGV"
      },
      "source": [
        "# writing out train data for max temperatures\n",
        "trainmax.to_csv('trainmax.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBgHypa9KMZS"
      },
      "source": [
        "# writing out train data for min temperatures\n",
        "trainmin.to_csv('trainmin.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz8OBFoOK9wF"
      },
      "source": [
        "# reading in the previous csv, just for simplicity\n",
        "trainmax=pd.read_csv('trainmax.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XgWEYTiPOQN"
      },
      "source": [
        "# transforming dataset\n",
        "max_dataset=trainmax.values.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGe_QYRUPwBn"
      },
      "source": [
        "# the first 7 columns are xi's these are given for feedforwarding,\n",
        "# and the 8th column is the wanted result (y) \n",
        "\n",
        "# making train, test, validation sets\n",
        "test_split = 0.1\n",
        "valid_split = 0.1\n",
        "\n",
        "X = max_dataset[:,0:7]\n",
        "Y = max_dataset[:,7]\n",
        "\n",
        "v_index = int(X.shape[0]*(1-valid_split-test_split))\n",
        "t_index = int(X.shape[0]*(1-test_split))\n",
        "\n",
        "X_test = X[t_index:]\n",
        "Y_test = Y[t_index:]\n",
        "X_valid = X[v_index:t_index]\n",
        "Y_valid = Y[v_index:t_index]\n",
        "X = X[:v_index]\n",
        "Y = Y[:v_index]\n",
        "\n",
        "# standardization of data\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler = StandardScaler().fit(X)\n",
        "X = scaler.transform(X)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE1bWnm8RCLM"
      },
      "source": [
        "# we are looking for the best model, and our patience is 10\n",
        "early_stopping=EarlyStopping(patience=10, verbose=1)\n",
        "checkpointer=ModelCheckpoint(filepath='weights.hdf5', save_best_only=True, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QrDOLLsP_1z",
        "outputId": "c474fa16-3fda-47ea-bbce-48d99f47a72a"
      },
      "source": [
        "# making the model, one hidden layer with 64 neurons, and sigmoid activation\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64, input_dim=X.shape[1], activation='sigmoid'))\n",
        "model.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "history=model.fit(X,Y,epochs=1000, \n",
        "                  verbose=2,\n",
        "                  validation_data=(X_valid, Y_valid),\n",
        "                  callbacks=[checkpointer, early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "57/57 - 1s - loss: 342.2574 - acc: 0.0234 - val_loss: 361.7103 - val_acc: 0.0179\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 361.71027, saving model to weights.hdf5\n",
            "Epoch 2/1000\n",
            "57/57 - 0s - loss: 270.6031 - acc: 0.0212 - val_loss: 284.9358 - val_acc: 0.0223\n",
            "\n",
            "Epoch 00002: val_loss improved from 361.71027 to 284.93582, saving model to weights.hdf5\n",
            "Epoch 3/1000\n",
            "57/57 - 0s - loss: 210.8067 - acc: 0.0251 - val_loss: 221.4747 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00003: val_loss improved from 284.93582 to 221.47470, saving model to weights.hdf5\n",
            "Epoch 4/1000\n",
            "57/57 - 0s - loss: 161.6841 - acc: 0.0256 - val_loss: 169.3178 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00004: val_loss improved from 221.47470 to 169.31778, saving model to weights.hdf5\n",
            "Epoch 5/1000\n",
            "57/57 - 0s - loss: 122.7103 - acc: 0.0251 - val_loss: 128.2363 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00005: val_loss improved from 169.31778 to 128.23625, saving model to weights.hdf5\n",
            "Epoch 6/1000\n",
            "57/57 - 0s - loss: 92.0486 - acc: 0.0251 - val_loss: 95.5802 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00006: val_loss improved from 128.23625 to 95.58021, saving model to weights.hdf5\n",
            "Epoch 7/1000\n",
            "57/57 - 0s - loss: 68.3144 - acc: 0.0251 - val_loss: 70.6530 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00007: val_loss improved from 95.58021 to 70.65302, saving model to weights.hdf5\n",
            "Epoch 8/1000\n",
            "57/57 - 0s - loss: 50.5018 - acc: 0.0251 - val_loss: 52.0491 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00008: val_loss improved from 70.65302 to 52.04914, saving model to weights.hdf5\n",
            "Epoch 9/1000\n",
            "57/57 - 0s - loss: 38.2268 - acc: 0.0251 - val_loss: 39.2850 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00009: val_loss improved from 52.04914 to 39.28503, saving model to weights.hdf5\n",
            "Epoch 10/1000\n",
            "57/57 - 0s - loss: 29.8746 - acc: 0.0251 - val_loss: 30.5007 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00010: val_loss improved from 39.28503 to 30.50070, saving model to weights.hdf5\n",
            "Epoch 11/1000\n",
            "57/57 - 0s - loss: 24.6715 - acc: 0.0251 - val_loss: 24.9798 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00011: val_loss improved from 30.50070 to 24.97981, saving model to weights.hdf5\n",
            "Epoch 12/1000\n",
            "57/57 - 0s - loss: 21.5528 - acc: 0.0251 - val_loss: 21.5517 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00012: val_loss improved from 24.97981 to 21.55169, saving model to weights.hdf5\n",
            "Epoch 13/1000\n",
            "57/57 - 0s - loss: 19.7299 - acc: 0.0251 - val_loss: 19.3718 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00013: val_loss improved from 21.55169 to 19.37175, saving model to weights.hdf5\n",
            "Epoch 14/1000\n",
            "57/57 - 0s - loss: 18.6199 - acc: 0.0251 - val_loss: 17.9638 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00014: val_loss improved from 19.37175 to 17.96382, saving model to weights.hdf5\n",
            "Epoch 15/1000\n",
            "57/57 - 0s - loss: 17.9491 - acc: 0.0251 - val_loss: 17.0720 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00015: val_loss improved from 17.96382 to 17.07196, saving model to weights.hdf5\n",
            "Epoch 16/1000\n",
            "57/57 - 0s - loss: 17.4607 - acc: 0.0251 - val_loss: 16.4137 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00016: val_loss improved from 17.07196 to 16.41367, saving model to weights.hdf5\n",
            "Epoch 17/1000\n",
            "57/57 - 0s - loss: 17.0810 - acc: 0.0251 - val_loss: 15.8649 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00017: val_loss improved from 16.41367 to 15.86487, saving model to weights.hdf5\n",
            "Epoch 18/1000\n",
            "57/57 - 0s - loss: 16.7521 - acc: 0.0251 - val_loss: 15.4907 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00018: val_loss improved from 15.86487 to 15.49066, saving model to weights.hdf5\n",
            "Epoch 19/1000\n",
            "57/57 - 0s - loss: 16.4510 - acc: 0.0251 - val_loss: 15.1513 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00019: val_loss improved from 15.49066 to 15.15126, saving model to weights.hdf5\n",
            "Epoch 20/1000\n",
            "57/57 - 0s - loss: 16.1617 - acc: 0.0251 - val_loss: 14.8639 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00020: val_loss improved from 15.15126 to 14.86393, saving model to weights.hdf5\n",
            "Epoch 21/1000\n",
            "57/57 - 0s - loss: 15.8734 - acc: 0.0251 - val_loss: 14.5524 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00021: val_loss improved from 14.86393 to 14.55237, saving model to weights.hdf5\n",
            "Epoch 22/1000\n",
            "57/57 - 0s - loss: 15.5973 - acc: 0.0251 - val_loss: 14.2485 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00022: val_loss improved from 14.55237 to 14.24855, saving model to weights.hdf5\n",
            "Epoch 23/1000\n",
            "57/57 - 0s - loss: 15.3364 - acc: 0.0251 - val_loss: 14.0193 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00023: val_loss improved from 14.24855 to 14.01927, saving model to weights.hdf5\n",
            "Epoch 24/1000\n",
            "57/57 - 0s - loss: 15.0805 - acc: 0.0251 - val_loss: 13.7894 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00024: val_loss improved from 14.01927 to 13.78937, saving model to weights.hdf5\n",
            "Epoch 25/1000\n",
            "57/57 - 0s - loss: 14.8347 - acc: 0.0251 - val_loss: 13.5535 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00025: val_loss improved from 13.78937 to 13.55353, saving model to weights.hdf5\n",
            "Epoch 26/1000\n",
            "57/57 - 0s - loss: 14.6017 - acc: 0.0251 - val_loss: 13.3059 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00026: val_loss improved from 13.55353 to 13.30595, saving model to weights.hdf5\n",
            "Epoch 27/1000\n",
            "57/57 - 0s - loss: 14.3762 - acc: 0.0251 - val_loss: 13.1118 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00027: val_loss improved from 13.30595 to 13.11176, saving model to weights.hdf5\n",
            "Epoch 28/1000\n",
            "57/57 - 0s - loss: 14.1645 - acc: 0.0251 - val_loss: 12.9008 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00028: val_loss improved from 13.11176 to 12.90082, saving model to weights.hdf5\n",
            "Epoch 29/1000\n",
            "57/57 - 0s - loss: 13.9690 - acc: 0.0251 - val_loss: 12.6959 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00029: val_loss improved from 12.90082 to 12.69592, saving model to weights.hdf5\n",
            "Epoch 30/1000\n",
            "57/57 - 0s - loss: 13.7749 - acc: 0.0251 - val_loss: 12.5054 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00030: val_loss improved from 12.69592 to 12.50535, saving model to weights.hdf5\n",
            "Epoch 31/1000\n",
            "57/57 - 0s - loss: 13.5999 - acc: 0.0251 - val_loss: 12.3241 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00031: val_loss improved from 12.50535 to 12.32411, saving model to weights.hdf5\n",
            "Epoch 32/1000\n",
            "57/57 - 0s - loss: 13.4277 - acc: 0.0251 - val_loss: 12.1791 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00032: val_loss improved from 12.32411 to 12.17907, saving model to weights.hdf5\n",
            "Epoch 33/1000\n",
            "57/57 - 0s - loss: 13.2632 - acc: 0.0251 - val_loss: 12.0490 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00033: val_loss improved from 12.17907 to 12.04898, saving model to weights.hdf5\n",
            "Epoch 34/1000\n",
            "57/57 - 0s - loss: 13.1071 - acc: 0.0251 - val_loss: 11.9145 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00034: val_loss improved from 12.04898 to 11.91452, saving model to weights.hdf5\n",
            "Epoch 35/1000\n",
            "57/57 - 0s - loss: 12.9643 - acc: 0.0251 - val_loss: 11.7523 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00035: val_loss improved from 11.91452 to 11.75233, saving model to weights.hdf5\n",
            "Epoch 36/1000\n",
            "57/57 - 0s - loss: 12.8237 - acc: 0.0251 - val_loss: 11.6118 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00036: val_loss improved from 11.75233 to 11.61176, saving model to weights.hdf5\n",
            "Epoch 37/1000\n",
            "57/57 - 0s - loss: 12.6963 - acc: 0.0251 - val_loss: 11.5114 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00037: val_loss improved from 11.61176 to 11.51140, saving model to weights.hdf5\n",
            "Epoch 38/1000\n",
            "57/57 - 0s - loss: 12.5764 - acc: 0.0251 - val_loss: 11.3840 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00038: val_loss improved from 11.51140 to 11.38399, saving model to weights.hdf5\n",
            "Epoch 39/1000\n",
            "57/57 - 0s - loss: 12.4629 - acc: 0.0251 - val_loss: 11.2954 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00039: val_loss improved from 11.38399 to 11.29545, saving model to weights.hdf5\n",
            "Epoch 40/1000\n",
            "57/57 - 0s - loss: 12.3492 - acc: 0.0251 - val_loss: 11.1445 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00040: val_loss improved from 11.29545 to 11.14446, saving model to weights.hdf5\n",
            "Epoch 41/1000\n",
            "57/57 - 0s - loss: 12.2479 - acc: 0.0251 - val_loss: 11.0479 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00041: val_loss improved from 11.14446 to 11.04793, saving model to weights.hdf5\n",
            "Epoch 42/1000\n",
            "57/57 - 0s - loss: 12.1425 - acc: 0.0251 - val_loss: 10.9775 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00042: val_loss improved from 11.04793 to 10.97748, saving model to weights.hdf5\n",
            "Epoch 43/1000\n",
            "57/57 - 0s - loss: 12.0524 - acc: 0.0251 - val_loss: 10.8794 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00043: val_loss improved from 10.97748 to 10.87938, saving model to weights.hdf5\n",
            "Epoch 44/1000\n",
            "57/57 - 0s - loss: 11.9722 - acc: 0.0251 - val_loss: 10.8171 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00044: val_loss improved from 10.87938 to 10.81710, saving model to weights.hdf5\n",
            "Epoch 45/1000\n",
            "57/57 - 0s - loss: 11.8820 - acc: 0.0251 - val_loss: 10.7122 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00045: val_loss improved from 10.81710 to 10.71222, saving model to weights.hdf5\n",
            "Epoch 46/1000\n",
            "57/57 - 0s - loss: 11.8036 - acc: 0.0251 - val_loss: 10.6321 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00046: val_loss improved from 10.71222 to 10.63210, saving model to weights.hdf5\n",
            "Epoch 47/1000\n",
            "57/57 - 0s - loss: 11.7383 - acc: 0.0251 - val_loss: 10.5667 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00047: val_loss improved from 10.63210 to 10.56669, saving model to weights.hdf5\n",
            "Epoch 48/1000\n",
            "57/57 - 0s - loss: 11.6644 - acc: 0.0251 - val_loss: 10.5049 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00048: val_loss improved from 10.56669 to 10.50494, saving model to weights.hdf5\n",
            "Epoch 49/1000\n",
            "57/57 - 0s - loss: 11.5970 - acc: 0.0251 - val_loss: 10.4476 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00049: val_loss improved from 10.50494 to 10.44760, saving model to weights.hdf5\n",
            "Epoch 50/1000\n",
            "57/57 - 0s - loss: 11.5358 - acc: 0.0251 - val_loss: 10.4016 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00050: val_loss improved from 10.44760 to 10.40158, saving model to weights.hdf5\n",
            "Epoch 51/1000\n",
            "57/57 - 0s - loss: 11.4869 - acc: 0.0251 - val_loss: 10.3073 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00051: val_loss improved from 10.40158 to 10.30731, saving model to weights.hdf5\n",
            "Epoch 52/1000\n",
            "57/57 - 0s - loss: 11.4443 - acc: 0.0251 - val_loss: 10.3004 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00052: val_loss improved from 10.30731 to 10.30039, saving model to weights.hdf5\n",
            "Epoch 53/1000\n",
            "57/57 - 0s - loss: 11.3752 - acc: 0.0251 - val_loss: 10.2526 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00053: val_loss improved from 10.30039 to 10.25255, saving model to weights.hdf5\n",
            "Epoch 54/1000\n",
            "57/57 - 0s - loss: 11.3294 - acc: 0.0251 - val_loss: 10.1867 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00054: val_loss improved from 10.25255 to 10.18670, saving model to weights.hdf5\n",
            "Epoch 55/1000\n",
            "57/57 - 0s - loss: 11.2841 - acc: 0.0251 - val_loss: 10.1975 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 10.18670\n",
            "Epoch 56/1000\n",
            "57/57 - 0s - loss: 11.2476 - acc: 0.0251 - val_loss: 10.2146 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 10.18670\n",
            "Epoch 57/1000\n",
            "57/57 - 0s - loss: 11.1891 - acc: 0.0256 - val_loss: 10.0604 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00057: val_loss improved from 10.18670 to 10.06043, saving model to weights.hdf5\n",
            "Epoch 58/1000\n",
            "57/57 - 0s - loss: 11.1630 - acc: 0.0251 - val_loss: 10.0292 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00058: val_loss improved from 10.06043 to 10.02919, saving model to weights.hdf5\n",
            "Epoch 59/1000\n",
            "57/57 - 0s - loss: 11.1350 - acc: 0.0251 - val_loss: 10.0043 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00059: val_loss improved from 10.02919 to 10.00429, saving model to weights.hdf5\n",
            "Epoch 60/1000\n",
            "57/57 - 0s - loss: 11.0851 - acc: 0.0256 - val_loss: 9.9867 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00060: val_loss improved from 10.00429 to 9.98672, saving model to weights.hdf5\n",
            "Epoch 61/1000\n",
            "57/57 - 0s - loss: 11.0693 - acc: 0.0256 - val_loss: 9.9697 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00061: val_loss improved from 9.98672 to 9.96972, saving model to weights.hdf5\n",
            "Epoch 62/1000\n",
            "57/57 - 0s - loss: 11.0380 - acc: 0.0256 - val_loss: 9.9269 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00062: val_loss improved from 9.96972 to 9.92686, saving model to weights.hdf5\n",
            "Epoch 63/1000\n",
            "57/57 - 0s - loss: 11.0001 - acc: 0.0256 - val_loss: 9.9215 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00063: val_loss improved from 9.92686 to 9.92149, saving model to weights.hdf5\n",
            "Epoch 64/1000\n",
            "57/57 - 0s - loss: 10.9634 - acc: 0.0256 - val_loss: 9.9109 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00064: val_loss improved from 9.92149 to 9.91091, saving model to weights.hdf5\n",
            "Epoch 65/1000\n",
            "57/57 - 0s - loss: 10.9315 - acc: 0.0256 - val_loss: 9.9177 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 9.91091\n",
            "Epoch 66/1000\n",
            "57/57 - 0s - loss: 10.9007 - acc: 0.0256 - val_loss: 9.8388 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00066: val_loss improved from 9.91091 to 9.83883, saving model to weights.hdf5\n",
            "Epoch 67/1000\n",
            "57/57 - 0s - loss: 10.8758 - acc: 0.0256 - val_loss: 9.8533 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 9.83883\n",
            "Epoch 68/1000\n",
            "57/57 - 0s - loss: 10.8824 - acc: 0.0256 - val_loss: 9.8048 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00068: val_loss improved from 9.83883 to 9.80481, saving model to weights.hdf5\n",
            "Epoch 69/1000\n",
            "57/57 - 0s - loss: 10.8356 - acc: 0.0256 - val_loss: 9.8013 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00069: val_loss improved from 9.80481 to 9.80130, saving model to weights.hdf5\n",
            "Epoch 70/1000\n",
            "57/57 - 0s - loss: 10.8208 - acc: 0.0256 - val_loss: 9.7422 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00070: val_loss improved from 9.80130 to 9.74218, saving model to weights.hdf5\n",
            "Epoch 71/1000\n",
            "57/57 - 0s - loss: 10.8229 - acc: 0.0256 - val_loss: 9.7258 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00071: val_loss improved from 9.74218 to 9.72578, saving model to weights.hdf5\n",
            "Epoch 72/1000\n",
            "57/57 - 0s - loss: 10.7836 - acc: 0.0256 - val_loss: 9.7200 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00072: val_loss improved from 9.72578 to 9.72004, saving model to weights.hdf5\n",
            "Epoch 73/1000\n",
            "57/57 - 0s - loss: 10.7498 - acc: 0.0256 - val_loss: 9.7545 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 9.72004\n",
            "Epoch 74/1000\n",
            "57/57 - 0s - loss: 10.7357 - acc: 0.0256 - val_loss: 9.6926 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00074: val_loss improved from 9.72004 to 9.69264, saving model to weights.hdf5\n",
            "Epoch 75/1000\n",
            "57/57 - 0s - loss: 10.7204 - acc: 0.0256 - val_loss: 9.7043 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 9.69264\n",
            "Epoch 76/1000\n",
            "57/57 - 0s - loss: 10.7374 - acc: 0.0256 - val_loss: 9.7090 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 9.69264\n",
            "Epoch 77/1000\n",
            "57/57 - 0s - loss: 10.7029 - acc: 0.0256 - val_loss: 9.7536 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 9.69264\n",
            "Epoch 78/1000\n",
            "57/57 - 0s - loss: 10.6808 - acc: 0.0256 - val_loss: 9.6394 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00078: val_loss improved from 9.69264 to 9.63936, saving model to weights.hdf5\n",
            "Epoch 79/1000\n",
            "57/57 - 0s - loss: 10.6600 - acc: 0.0256 - val_loss: 9.6311 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00079: val_loss improved from 9.63936 to 9.63114, saving model to weights.hdf5\n",
            "Epoch 80/1000\n",
            "57/57 - 0s - loss: 10.6409 - acc: 0.0256 - val_loss: 9.6381 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 9.63114\n",
            "Epoch 81/1000\n",
            "57/57 - 0s - loss: 10.6358 - acc: 0.0256 - val_loss: 9.6153 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00081: val_loss improved from 9.63114 to 9.61532, saving model to weights.hdf5\n",
            "Epoch 82/1000\n",
            "57/57 - 0s - loss: 10.6176 - acc: 0.0256 - val_loss: 9.6665 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 9.61532\n",
            "Epoch 83/1000\n",
            "57/57 - 0s - loss: 10.6218 - acc: 0.0256 - val_loss: 9.5730 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00083: val_loss improved from 9.61532 to 9.57303, saving model to weights.hdf5\n",
            "Epoch 84/1000\n",
            "57/57 - 0s - loss: 10.6064 - acc: 0.0256 - val_loss: 9.5935 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 9.57303\n",
            "Epoch 85/1000\n",
            "57/57 - 0s - loss: 10.5831 - acc: 0.0251 - val_loss: 9.6164 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 9.57303\n",
            "Epoch 86/1000\n",
            "57/57 - 0s - loss: 10.5884 - acc: 0.0256 - val_loss: 9.6147 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 9.57303\n",
            "Epoch 87/1000\n",
            "57/57 - 0s - loss: 10.5676 - acc: 0.0256 - val_loss: 9.5974 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 9.57303\n",
            "Epoch 88/1000\n",
            "57/57 - 0s - loss: 10.5484 - acc: 0.0256 - val_loss: 9.5479 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00088: val_loss improved from 9.57303 to 9.54791, saving model to weights.hdf5\n",
            "Epoch 89/1000\n",
            "57/57 - 0s - loss: 10.5491 - acc: 0.0256 - val_loss: 9.4995 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00089: val_loss improved from 9.54791 to 9.49950, saving model to weights.hdf5\n",
            "Epoch 90/1000\n",
            "57/57 - 0s - loss: 10.5745 - acc: 0.0251 - val_loss: 9.4978 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00090: val_loss improved from 9.49950 to 9.49777, saving model to weights.hdf5\n",
            "Epoch 91/1000\n",
            "57/57 - 0s - loss: 10.4913 - acc: 0.0251 - val_loss: 9.6727 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 9.49777\n",
            "Epoch 92/1000\n",
            "57/57 - 0s - loss: 10.5089 - acc: 0.0251 - val_loss: 9.5040 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 9.49777\n",
            "Epoch 93/1000\n",
            "57/57 - 0s - loss: 10.5157 - acc: 0.0251 - val_loss: 9.5068 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 9.49777\n",
            "Epoch 94/1000\n",
            "57/57 - 0s - loss: 10.4923 - acc: 0.0256 - val_loss: 9.5301 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 9.49777\n",
            "Epoch 95/1000\n",
            "57/57 - 0s - loss: 10.5059 - acc: 0.0251 - val_loss: 9.5572 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 9.49777\n",
            "Epoch 96/1000\n",
            "57/57 - 0s - loss: 10.5071 - acc: 0.0256 - val_loss: 9.4829 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00096: val_loss improved from 9.49777 to 9.48286, saving model to weights.hdf5\n",
            "Epoch 97/1000\n",
            "57/57 - 0s - loss: 10.4653 - acc: 0.0251 - val_loss: 9.4589 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00097: val_loss improved from 9.48286 to 9.45894, saving model to weights.hdf5\n",
            "Epoch 98/1000\n",
            "57/57 - 0s - loss: 10.4865 - acc: 0.0256 - val_loss: 9.4845 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 9.45894\n",
            "Epoch 99/1000\n",
            "57/57 - 0s - loss: 10.4535 - acc: 0.0251 - val_loss: 9.4915 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 9.45894\n",
            "Epoch 100/1000\n",
            "57/57 - 0s - loss: 10.4526 - acc: 0.0251 - val_loss: 9.4504 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00100: val_loss improved from 9.45894 to 9.45041, saving model to weights.hdf5\n",
            "Epoch 101/1000\n",
            "57/57 - 0s - loss: 10.4486 - acc: 0.0251 - val_loss: 9.5533 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 9.45041\n",
            "Epoch 102/1000\n",
            "57/57 - 0s - loss: 10.4495 - acc: 0.0251 - val_loss: 9.5544 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 9.45041\n",
            "Epoch 103/1000\n",
            "57/57 - 0s - loss: 10.4376 - acc: 0.0251 - val_loss: 9.4485 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00103: val_loss improved from 9.45041 to 9.44845, saving model to weights.hdf5\n",
            "Epoch 104/1000\n",
            "57/57 - 0s - loss: 10.4374 - acc: 0.0251 - val_loss: 9.5610 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 9.44845\n",
            "Epoch 105/1000\n",
            "57/57 - 0s - loss: 10.3994 - acc: 0.0251 - val_loss: 9.4372 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00105: val_loss improved from 9.44845 to 9.43717, saving model to weights.hdf5\n",
            "Epoch 106/1000\n",
            "57/57 - 0s - loss: 10.4209 - acc: 0.0251 - val_loss: 9.5003 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 9.43717\n",
            "Epoch 107/1000\n",
            "57/57 - 0s - loss: 10.3922 - acc: 0.0251 - val_loss: 9.4539 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 9.43717\n",
            "Epoch 108/1000\n",
            "57/57 - 0s - loss: 10.3999 - acc: 0.0251 - val_loss: 9.4773 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 9.43717\n",
            "Epoch 109/1000\n",
            "57/57 - 0s - loss: 10.3885 - acc: 0.0251 - val_loss: 9.4653 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 9.43717\n",
            "Epoch 110/1000\n",
            "57/57 - 0s - loss: 10.3972 - acc: 0.0251 - val_loss: 9.4449 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 9.43717\n",
            "Epoch 111/1000\n",
            "57/57 - 0s - loss: 10.3951 - acc: 0.0251 - val_loss: 9.4075 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00111: val_loss improved from 9.43717 to 9.40747, saving model to weights.hdf5\n",
            "Epoch 112/1000\n",
            "57/57 - 0s - loss: 10.4204 - acc: 0.0251 - val_loss: 9.4086 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 9.40747\n",
            "Epoch 113/1000\n",
            "57/57 - 0s - loss: 10.3747 - acc: 0.0251 - val_loss: 9.4048 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00113: val_loss improved from 9.40747 to 9.40481, saving model to weights.hdf5\n",
            "Epoch 114/1000\n",
            "57/57 - 0s - loss: 10.3628 - acc: 0.0251 - val_loss: 9.4256 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 9.40481\n",
            "Epoch 115/1000\n",
            "57/57 - 0s - loss: 10.3687 - acc: 0.0251 - val_loss: 9.4351 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 9.40481\n",
            "Epoch 116/1000\n",
            "57/57 - 0s - loss: 10.3474 - acc: 0.0251 - val_loss: 9.3791 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00116: val_loss improved from 9.40481 to 9.37913, saving model to weights.hdf5\n",
            "Epoch 117/1000\n",
            "57/57 - 0s - loss: 10.3513 - acc: 0.0251 - val_loss: 9.3984 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 9.37913\n",
            "Epoch 118/1000\n",
            "57/57 - 0s - loss: 10.3362 - acc: 0.0251 - val_loss: 9.4684 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 9.37913\n",
            "Epoch 119/1000\n",
            "57/57 - 0s - loss: 10.3239 - acc: 0.0251 - val_loss: 9.3764 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00119: val_loss improved from 9.37913 to 9.37635, saving model to weights.hdf5\n",
            "Epoch 120/1000\n",
            "57/57 - 0s - loss: 10.3332 - acc: 0.0251 - val_loss: 9.4907 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 9.37635\n",
            "Epoch 121/1000\n",
            "57/57 - 0s - loss: 10.3392 - acc: 0.0256 - val_loss: 9.4210 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 9.37635\n",
            "Epoch 122/1000\n",
            "57/57 - 0s - loss: 10.3276 - acc: 0.0251 - val_loss: 9.4206 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 9.37635\n",
            "Epoch 123/1000\n",
            "57/57 - 0s - loss: 10.3119 - acc: 0.0251 - val_loss: 9.4288 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 9.37635\n",
            "Epoch 124/1000\n",
            "57/57 - 0s - loss: 10.3192 - acc: 0.0251 - val_loss: 9.5148 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 9.37635\n",
            "Epoch 125/1000\n",
            "57/57 - 0s - loss: 10.3123 - acc: 0.0251 - val_loss: 9.4257 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 9.37635\n",
            "Epoch 126/1000\n",
            "57/57 - 0s - loss: 10.2900 - acc: 0.0251 - val_loss: 9.5115 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 9.37635\n",
            "Epoch 127/1000\n",
            "57/57 - 0s - loss: 10.3074 - acc: 0.0251 - val_loss: 9.4434 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 9.37635\n",
            "Epoch 128/1000\n",
            "57/57 - 0s - loss: 10.2952 - acc: 0.0251 - val_loss: 9.3721 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00128: val_loss improved from 9.37635 to 9.37214, saving model to weights.hdf5\n",
            "Epoch 129/1000\n",
            "57/57 - 0s - loss: 10.2874 - acc: 0.0256 - val_loss: 9.3629 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00129: val_loss improved from 9.37214 to 9.36289, saving model to weights.hdf5\n",
            "Epoch 130/1000\n",
            "57/57 - 0s - loss: 10.2916 - acc: 0.0256 - val_loss: 9.3755 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 9.36289\n",
            "Epoch 131/1000\n",
            "57/57 - 0s - loss: 10.2843 - acc: 0.0245 - val_loss: 9.3334 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00131: val_loss improved from 9.36289 to 9.33335, saving model to weights.hdf5\n",
            "Epoch 132/1000\n",
            "57/57 - 0s - loss: 10.3132 - acc: 0.0251 - val_loss: 9.3642 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 9.33335\n",
            "Epoch 133/1000\n",
            "57/57 - 0s - loss: 10.2893 - acc: 0.0245 - val_loss: 9.3511 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 9.33335\n",
            "Epoch 134/1000\n",
            "57/57 - 0s - loss: 10.2694 - acc: 0.0256 - val_loss: 9.4125 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 9.33335\n",
            "Epoch 135/1000\n",
            "57/57 - 0s - loss: 10.2912 - acc: 0.0256 - val_loss: 9.3698 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 9.33335\n",
            "Epoch 136/1000\n",
            "57/57 - 0s - loss: 10.2753 - acc: 0.0256 - val_loss: 9.3308 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00136: val_loss improved from 9.33335 to 9.33085, saving model to weights.hdf5\n",
            "Epoch 137/1000\n",
            "57/57 - 0s - loss: 10.2664 - acc: 0.0262 - val_loss: 9.4082 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 9.33085\n",
            "Epoch 138/1000\n",
            "57/57 - 0s - loss: 10.2395 - acc: 0.0256 - val_loss: 9.3679 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 9.33085\n",
            "Epoch 139/1000\n",
            "57/57 - 0s - loss: 10.2548 - acc: 0.0262 - val_loss: 9.3858 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 9.33085\n",
            "Epoch 140/1000\n",
            "57/57 - 0s - loss: 10.2438 - acc: 0.0256 - val_loss: 9.3524 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 9.33085\n",
            "Epoch 141/1000\n",
            "57/57 - 0s - loss: 10.2567 - acc: 0.0256 - val_loss: 9.3539 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 9.33085\n",
            "Epoch 142/1000\n",
            "57/57 - 0s - loss: 10.2463 - acc: 0.0262 - val_loss: 9.3518 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 9.33085\n",
            "Epoch 143/1000\n",
            "57/57 - 0s - loss: 10.2458 - acc: 0.0251 - val_loss: 9.3570 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 9.33085\n",
            "Epoch 144/1000\n",
            "57/57 - 0s - loss: 10.2413 - acc: 0.0256 - val_loss: 9.3737 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 9.33085\n",
            "Epoch 145/1000\n",
            "57/57 - 0s - loss: 10.2409 - acc: 0.0256 - val_loss: 9.4168 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 9.33085\n",
            "Epoch 146/1000\n",
            "57/57 - 0s - loss: 10.2421 - acc: 0.0251 - val_loss: 9.3575 - val_acc: 0.0089\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 9.33085\n",
            "Epoch 00146: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfvDIePXTPOJ",
        "outputId": "40f580c4-0424-4a12-e379-c17335c5ebe0"
      },
      "source": [
        "# the mse of the test dataset and the prediction of the model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "model = load_model('weights.hdf5')\n",
        "preds = model.predict(X_test)\n",
        "test_err = mean_squared_error(Y_test,preds)\n",
        "print(\"\\nTesterror: %f\" % (test_err))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testerror: 10.181460\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h61xP3k_VD01"
      },
      "source": [
        "# this is for max dataset\n",
        "# predicting the weather, given 7 temperatures as last_one_week,\n",
        "# and when we are curious about weather as prediction time\n",
        "# recursion function, the result is the input of the next calculating\n",
        "def weather_prediction_1(last_one_week,prediction_time):\n",
        "  if prediction_time>0:\n",
        "    prediction=model.predict(scaler.transform(last_one_week))\n",
        "    # making the next seven length sample\n",
        "    next_last_week=np.concatenate((last_one_week,prediction), axis=1)\n",
        "    next_last_week=[np.delete(next_last_week,0)]\n",
        "    #print(next_last_week)\n",
        "    # calculating the next prediction\n",
        "    weather_prediction_1(next_last_week,prediction_time-1)\n",
        "  else:\n",
        "    print(last_one_week[0][-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJBreaqQUl_Y",
        "outputId": "1222aa85-df10-4453-8971-64552927e52b"
      },
      "source": [
        "# an example for 8th of November\n",
        "weather_prediction_1([[14,10,12,16,12,13,11]],1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.104191780090332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZbHbQ6abRTv"
      },
      "source": [
        "# reading in the earlier csv, just for simplicity\n",
        "trainmin=pd.read_csv('trainmin.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw2C03mruNXx"
      },
      "source": [
        "# transforming dataset for min temperatures\n",
        "min_dataset=trainmin.values.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgGtD442uUqw"
      },
      "source": [
        "# the first 7 columns are xi's these are given for feedforwarding,\n",
        "# and the 8th column is the wanted result (y) \n",
        "\n",
        "# making train, test, validation sets\n",
        "X_2 = min_dataset[:,0:7]\n",
        "Y_2 = min_dataset[:,7]\n",
        "\n",
        "v_index = int(X_2.shape[0]*(1-valid_split-test_split))\n",
        "t_index = int(X_2.shape[0]*(1-test_split))\n",
        "\n",
        "X_test_2 = X_2[t_index:]\n",
        "Y_test_2 = Y_2[t_index:]\n",
        "X_valid_2 = X_2[v_index:t_index]\n",
        "Y_valid_2 = Y_2[v_index:t_index]\n",
        "X_2 = X_2[:v_index]\n",
        "Y_2 = Y_2[:v_index]\n",
        "\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler_2 = StandardScaler().fit(X_2)\n",
        "X_2 = scaler_2.transform(X_2)\n",
        "X_valid_2 = scaler_2.transform(X_valid_2)\n",
        "X_test_2 = scaler_2.transform(X_test_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX_qFFBpuVtM"
      },
      "source": [
        "early_stopping_2=EarlyStopping(patience=10, verbose=1)\n",
        "checkpointer_2=ModelCheckpoint(filepath='weights_2.hdf5', save_best_only=True, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Juc5r78WvMbk",
        "outputId": "4fb7a7a1-9f45-4037-c20b-1df75bb2428c"
      },
      "source": [
        "# making another model for min temperatures, one hidden layer with 64 neurons, and sigmoid activation\n",
        "model_2 = Sequential()\n",
        "model_2.add(Dense(units=64, input_dim=X_2.shape[1], activation='sigmoid'))\n",
        "model_2.add(Dense(units=1, activation='linear'))\n",
        "\n",
        "model_2.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "history=model_2.fit(X_2,Y_2,epochs=1000, \n",
        "                  verbose=2,\n",
        "                  validation_data=(X_valid_2, Y_valid_2),\n",
        "                  callbacks=[checkpointer_2, early_stopping_2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "57/57 - 1s - loss: 78.1400 - acc: 0.0462 - val_loss: 78.4771 - val_acc: 0.0491\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 78.47712, saving model to weights_2.hdf5\n",
            "Epoch 2/1000\n",
            "57/57 - 0s - loss: 56.4395 - acc: 0.0468 - val_loss: 54.2166 - val_acc: 0.0491\n",
            "\n",
            "Epoch 00002: val_loss improved from 78.47712 to 54.21665, saving model to weights_2.hdf5\n",
            "Epoch 3/1000\n",
            "57/57 - 0s - loss: 40.6265 - acc: 0.0468 - val_loss: 37.2507 - val_acc: 0.0491\n",
            "\n",
            "Epoch 00003: val_loss improved from 54.21665 to 37.25068, saving model to weights_2.hdf5\n",
            "Epoch 4/1000\n",
            "57/57 - 0s - loss: 29.7040 - acc: 0.0507 - val_loss: 26.2166 - val_acc: 0.0491\n",
            "\n",
            "Epoch 00004: val_loss improved from 37.25068 to 26.21662, saving model to weights_2.hdf5\n",
            "Epoch 5/1000\n",
            "57/57 - 0s - loss: 22.8174 - acc: 0.0540 - val_loss: 19.6752 - val_acc: 0.0446\n",
            "\n",
            "Epoch 00005: val_loss improved from 26.21662 to 19.67520, saving model to weights_2.hdf5\n",
            "Epoch 6/1000\n",
            "57/57 - 0s - loss: 18.6668 - acc: 0.0529 - val_loss: 15.9243 - val_acc: 0.0491\n",
            "\n",
            "Epoch 00006: val_loss improved from 19.67520 to 15.92429, saving model to weights_2.hdf5\n",
            "Epoch 7/1000\n",
            "57/57 - 0s - loss: 16.3761 - acc: 0.0546 - val_loss: 13.8857 - val_acc: 0.0402\n",
            "\n",
            "Epoch 00007: val_loss improved from 15.92429 to 13.88575, saving model to weights_2.hdf5\n",
            "Epoch 8/1000\n",
            "57/57 - 0s - loss: 15.1507 - acc: 0.0546 - val_loss: 12.8006 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00008: val_loss improved from 13.88575 to 12.80061, saving model to weights_2.hdf5\n",
            "Epoch 9/1000\n",
            "57/57 - 0s - loss: 14.4801 - acc: 0.0551 - val_loss: 12.2019 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00009: val_loss improved from 12.80061 to 12.20186, saving model to weights_2.hdf5\n",
            "Epoch 10/1000\n",
            "57/57 - 0s - loss: 14.0842 - acc: 0.0551 - val_loss: 11.8217 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00010: val_loss improved from 12.20186 to 11.82174, saving model to weights_2.hdf5\n",
            "Epoch 11/1000\n",
            "57/57 - 0s - loss: 13.7712 - acc: 0.0540 - val_loss: 11.5538 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00011: val_loss improved from 11.82174 to 11.55381, saving model to weights_2.hdf5\n",
            "Epoch 12/1000\n",
            "57/57 - 0s - loss: 13.4769 - acc: 0.0540 - val_loss: 11.3128 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00012: val_loss improved from 11.55381 to 11.31282, saving model to weights_2.hdf5\n",
            "Epoch 13/1000\n",
            "57/57 - 0s - loss: 13.1934 - acc: 0.0546 - val_loss: 11.1614 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00013: val_loss improved from 11.31282 to 11.16138, saving model to weights_2.hdf5\n",
            "Epoch 14/1000\n",
            "57/57 - 0s - loss: 12.8933 - acc: 0.0546 - val_loss: 10.9456 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00014: val_loss improved from 11.16138 to 10.94559, saving model to weights_2.hdf5\n",
            "Epoch 15/1000\n",
            "57/57 - 0s - loss: 12.5906 - acc: 0.0546 - val_loss: 10.7677 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00015: val_loss improved from 10.94559 to 10.76768, saving model to weights_2.hdf5\n",
            "Epoch 16/1000\n",
            "57/57 - 0s - loss: 12.2713 - acc: 0.0551 - val_loss: 10.5486 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00016: val_loss improved from 10.76768 to 10.54856, saving model to weights_2.hdf5\n",
            "Epoch 17/1000\n",
            "57/57 - 0s - loss: 11.9531 - acc: 0.0557 - val_loss: 10.3623 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00017: val_loss improved from 10.54856 to 10.36233, saving model to weights_2.hdf5\n",
            "Epoch 18/1000\n",
            "57/57 - 0s - loss: 11.6471 - acc: 0.0562 - val_loss: 10.2037 - val_acc: 0.0402\n",
            "\n",
            "Epoch 00018: val_loss improved from 10.36233 to 10.20367, saving model to weights_2.hdf5\n",
            "Epoch 19/1000\n",
            "57/57 - 0s - loss: 11.3441 - acc: 0.0557 - val_loss: 10.0752 - val_acc: 0.0402\n",
            "\n",
            "Epoch 00019: val_loss improved from 10.20367 to 10.07523, saving model to weights_2.hdf5\n",
            "Epoch 20/1000\n",
            "57/57 - 0s - loss: 11.0785 - acc: 0.0551 - val_loss: 9.9139 - val_acc: 0.0402\n",
            "\n",
            "Epoch 00020: val_loss improved from 10.07523 to 9.91395, saving model to weights_2.hdf5\n",
            "Epoch 21/1000\n",
            "57/57 - 0s - loss: 10.8058 - acc: 0.0540 - val_loss: 9.7751 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00021: val_loss improved from 9.91395 to 9.77512, saving model to weights_2.hdf5\n",
            "Epoch 22/1000\n",
            "57/57 - 0s - loss: 10.5611 - acc: 0.0540 - val_loss: 9.6547 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00022: val_loss improved from 9.77512 to 9.65467, saving model to weights_2.hdf5\n",
            "Epoch 23/1000\n",
            "57/57 - 0s - loss: 10.3547 - acc: 0.0535 - val_loss: 9.5438 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00023: val_loss improved from 9.65467 to 9.54383, saving model to weights_2.hdf5\n",
            "Epoch 24/1000\n",
            "57/57 - 0s - loss: 10.1474 - acc: 0.0535 - val_loss: 9.4502 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00024: val_loss improved from 9.54383 to 9.45016, saving model to weights_2.hdf5\n",
            "Epoch 25/1000\n",
            "57/57 - 0s - loss: 9.9672 - acc: 0.0535 - val_loss: 9.3763 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00025: val_loss improved from 9.45016 to 9.37627, saving model to weights_2.hdf5\n",
            "Epoch 26/1000\n",
            "57/57 - 0s - loss: 9.8116 - acc: 0.0535 - val_loss: 9.3104 - val_acc: 0.0402\n",
            "\n",
            "Epoch 00026: val_loss improved from 9.37627 to 9.31038, saving model to weights_2.hdf5\n",
            "Epoch 27/1000\n",
            "57/57 - 0s - loss: 9.6667 - acc: 0.0529 - val_loss: 9.2825 - val_acc: 0.0402\n",
            "\n",
            "Epoch 00027: val_loss improved from 9.31038 to 9.28247, saving model to weights_2.hdf5\n",
            "Epoch 28/1000\n",
            "57/57 - 0s - loss: 9.5294 - acc: 0.0523 - val_loss: 9.1976 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00028: val_loss improved from 9.28247 to 9.19762, saving model to weights_2.hdf5\n",
            "Epoch 29/1000\n",
            "57/57 - 0s - loss: 9.4191 - acc: 0.0523 - val_loss: 9.1357 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00029: val_loss improved from 9.19762 to 9.13573, saving model to weights_2.hdf5\n",
            "Epoch 30/1000\n",
            "57/57 - 0s - loss: 9.3160 - acc: 0.0529 - val_loss: 9.0674 - val_acc: 0.0357\n",
            "\n",
            "Epoch 00030: val_loss improved from 9.13573 to 9.06737, saving model to weights_2.hdf5\n",
            "Epoch 31/1000\n",
            "57/57 - 0s - loss: 9.2176 - acc: 0.0523 - val_loss: 9.0359 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00031: val_loss improved from 9.06737 to 9.03586, saving model to weights_2.hdf5\n",
            "Epoch 32/1000\n",
            "57/57 - 0s - loss: 9.1379 - acc: 0.0523 - val_loss: 9.0493 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 9.03586\n",
            "Epoch 33/1000\n",
            "57/57 - 0s - loss: 9.0707 - acc: 0.0523 - val_loss: 8.9907 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00033: val_loss improved from 9.03586 to 8.99070, saving model to weights_2.hdf5\n",
            "Epoch 34/1000\n",
            "57/57 - 0s - loss: 9.0057 - acc: 0.0523 - val_loss: 8.9949 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 8.99070\n",
            "Epoch 35/1000\n",
            "57/57 - 0s - loss: 8.9468 - acc: 0.0523 - val_loss: 8.9561 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00035: val_loss improved from 8.99070 to 8.95611, saving model to weights_2.hdf5\n",
            "Epoch 36/1000\n",
            "57/57 - 0s - loss: 8.8850 - acc: 0.0523 - val_loss: 8.9214 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00036: val_loss improved from 8.95611 to 8.92141, saving model to weights_2.hdf5\n",
            "Epoch 37/1000\n",
            "57/57 - 0s - loss: 8.8238 - acc: 0.0518 - val_loss: 8.9484 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 8.92141\n",
            "Epoch 38/1000\n",
            "57/57 - 0s - loss: 8.7914 - acc: 0.0523 - val_loss: 8.8642 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00038: val_loss improved from 8.92141 to 8.86420, saving model to weights_2.hdf5\n",
            "Epoch 39/1000\n",
            "57/57 - 0s - loss: 8.7321 - acc: 0.0518 - val_loss: 8.9052 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 8.86420\n",
            "Epoch 40/1000\n",
            "57/57 - 0s - loss: 8.6981 - acc: 0.0512 - val_loss: 8.8282 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00040: val_loss improved from 8.86420 to 8.82823, saving model to weights_2.hdf5\n",
            "Epoch 41/1000\n",
            "57/57 - 0s - loss: 8.6697 - acc: 0.0518 - val_loss: 8.8558 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 8.82823\n",
            "Epoch 42/1000\n",
            "57/57 - 0s - loss: 8.6457 - acc: 0.0518 - val_loss: 8.8150 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00042: val_loss improved from 8.82823 to 8.81503, saving model to weights_2.hdf5\n",
            "Epoch 43/1000\n",
            "57/57 - 0s - loss: 8.6246 - acc: 0.0512 - val_loss: 8.8065 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00043: val_loss improved from 8.81503 to 8.80653, saving model to weights_2.hdf5\n",
            "Epoch 44/1000\n",
            "57/57 - 0s - loss: 8.5922 - acc: 0.0512 - val_loss: 8.7899 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00044: val_loss improved from 8.80653 to 8.78991, saving model to weights_2.hdf5\n",
            "Epoch 45/1000\n",
            "57/57 - 0s - loss: 8.5808 - acc: 0.0507 - val_loss: 8.7856 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00045: val_loss improved from 8.78991 to 8.78558, saving model to weights_2.hdf5\n",
            "Epoch 46/1000\n",
            "57/57 - 0s - loss: 8.5561 - acc: 0.0512 - val_loss: 8.8365 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 8.78558\n",
            "Epoch 47/1000\n",
            "57/57 - 0s - loss: 8.5521 - acc: 0.0512 - val_loss: 8.8341 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 8.78558\n",
            "Epoch 48/1000\n",
            "57/57 - 0s - loss: 8.5128 - acc: 0.0512 - val_loss: 8.7767 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00048: val_loss improved from 8.78558 to 8.77670, saving model to weights_2.hdf5\n",
            "Epoch 49/1000\n",
            "57/57 - 0s - loss: 8.5044 - acc: 0.0507 - val_loss: 8.7814 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 8.77670\n",
            "Epoch 50/1000\n",
            "57/57 - 0s - loss: 8.4821 - acc: 0.0518 - val_loss: 8.7964 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 8.77670\n",
            "Epoch 51/1000\n",
            "57/57 - 0s - loss: 8.4807 - acc: 0.0512 - val_loss: 8.7369 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00051: val_loss improved from 8.77670 to 8.73692, saving model to weights_2.hdf5\n",
            "Epoch 52/1000\n",
            "57/57 - 0s - loss: 8.4682 - acc: 0.0507 - val_loss: 8.7351 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00052: val_loss improved from 8.73692 to 8.73509, saving model to weights_2.hdf5\n",
            "Epoch 53/1000\n",
            "57/57 - 0s - loss: 8.4550 - acc: 0.0507 - val_loss: 8.8452 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 8.73509\n",
            "Epoch 54/1000\n",
            "57/57 - 0s - loss: 8.4374 - acc: 0.0518 - val_loss: 8.7581 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 8.73509\n",
            "Epoch 55/1000\n",
            "57/57 - 0s - loss: 8.4255 - acc: 0.0512 - val_loss: 8.7480 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 8.73509\n",
            "Epoch 56/1000\n",
            "57/57 - 0s - loss: 8.4177 - acc: 0.0507 - val_loss: 8.7404 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 8.73509\n",
            "Epoch 57/1000\n",
            "57/57 - 0s - loss: 8.4131 - acc: 0.0518 - val_loss: 8.7940 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 8.73509\n",
            "Epoch 58/1000\n",
            "57/57 - 0s - loss: 8.4199 - acc: 0.0501 - val_loss: 8.7467 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 8.73509\n",
            "Epoch 59/1000\n",
            "57/57 - 0s - loss: 8.4041 - acc: 0.0512 - val_loss: 8.7095 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00059: val_loss improved from 8.73509 to 8.70949, saving model to weights_2.hdf5\n",
            "Epoch 60/1000\n",
            "57/57 - 0s - loss: 8.4032 - acc: 0.0518 - val_loss: 8.7273 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 8.70949\n",
            "Epoch 61/1000\n",
            "57/57 - 0s - loss: 8.3793 - acc: 0.0523 - val_loss: 8.7953 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 8.70949\n",
            "Epoch 62/1000\n",
            "57/57 - 0s - loss: 8.3984 - acc: 0.0512 - val_loss: 8.7330 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 8.70949\n",
            "Epoch 63/1000\n",
            "57/57 - 0s - loss: 8.3796 - acc: 0.0507 - val_loss: 8.7566 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 8.70949\n",
            "Epoch 64/1000\n",
            "57/57 - 0s - loss: 8.3670 - acc: 0.0523 - val_loss: 8.7306 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 8.70949\n",
            "Epoch 65/1000\n",
            "57/57 - 0s - loss: 8.3608 - acc: 0.0507 - val_loss: 8.7352 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 8.70949\n",
            "Epoch 66/1000\n",
            "57/57 - 0s - loss: 8.3514 - acc: 0.0523 - val_loss: 8.7155 - val_acc: 0.0223\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 8.70949\n",
            "Epoch 67/1000\n",
            "57/57 - 0s - loss: 8.3568 - acc: 0.0512 - val_loss: 8.7041 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00067: val_loss improved from 8.70949 to 8.70414, saving model to weights_2.hdf5\n",
            "Epoch 68/1000\n",
            "57/57 - 0s - loss: 8.3448 - acc: 0.0512 - val_loss: 8.7159 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 8.70414\n",
            "Epoch 69/1000\n",
            "57/57 - 0s - loss: 8.3511 - acc: 0.0507 - val_loss: 8.7532 - val_acc: 0.0223\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 8.70414\n",
            "Epoch 70/1000\n",
            "57/57 - 0s - loss: 8.3315 - acc: 0.0512 - val_loss: 8.7329 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 8.70414\n",
            "Epoch 71/1000\n",
            "57/57 - 0s - loss: 8.3287 - acc: 0.0512 - val_loss: 8.7910 - val_acc: 0.0223\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 8.70414\n",
            "Epoch 72/1000\n",
            "57/57 - 0s - loss: 8.3212 - acc: 0.0518 - val_loss: 8.6974 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00072: val_loss improved from 8.70414 to 8.69743, saving model to weights_2.hdf5\n",
            "Epoch 73/1000\n",
            "57/57 - 0s - loss: 8.3445 - acc: 0.0518 - val_loss: 8.7299 - val_acc: 0.0223\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 8.69743\n",
            "Epoch 74/1000\n",
            "57/57 - 0s - loss: 8.3235 - acc: 0.0518 - val_loss: 8.7168 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 8.69743\n",
            "Epoch 75/1000\n",
            "57/57 - 0s - loss: 8.3186 - acc: 0.0518 - val_loss: 8.7235 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 8.69743\n",
            "Epoch 76/1000\n",
            "57/57 - 0s - loss: 8.3101 - acc: 0.0518 - val_loss: 8.7059 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 8.69743\n",
            "Epoch 77/1000\n",
            "57/57 - 0s - loss: 8.3054 - acc: 0.0512 - val_loss: 8.7825 - val_acc: 0.0223\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 8.69743\n",
            "Epoch 78/1000\n",
            "57/57 - 0s - loss: 8.3131 - acc: 0.0523 - val_loss: 8.7763 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 8.69743\n",
            "Epoch 79/1000\n",
            "57/57 - 0s - loss: 8.3049 - acc: 0.0512 - val_loss: 8.7351 - val_acc: 0.0312\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 8.69743\n",
            "Epoch 80/1000\n",
            "57/57 - 0s - loss: 8.3251 - acc: 0.0529 - val_loss: 8.7004 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 8.69743\n",
            "Epoch 81/1000\n",
            "57/57 - 0s - loss: 8.3006 - acc: 0.0507 - val_loss: 8.7464 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 8.69743\n",
            "Epoch 82/1000\n",
            "57/57 - 0s - loss: 8.2949 - acc: 0.0507 - val_loss: 8.7891 - val_acc: 0.0268\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 8.69743\n",
            "Epoch 00082: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vezWXBr2vjr5",
        "outputId": "7cba1869-e546-489f-957a-91a3745f31ea"
      },
      "source": [
        "# the mse of the test dataset and the prediction of the model for min temperatures\n",
        "model_2 = load_model('weights_2.hdf5')\n",
        "preds_2 = model_2.predict(X_test_2)\n",
        "test_err_2 = mean_squared_error(Y_test_2,preds_2)\n",
        "print(\"\\nTesterror: %f\" % (test_err_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testerror: 7.434148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHUujmAbvw5N"
      },
      "source": [
        "# this is for min dataset\n",
        "# predicting the weather, given 7 temperatures as last_one_week,\n",
        "# and when we are curious about weather as prediction time\n",
        "# recursion function, the result is the input of the next calculating\n",
        "def weather_prediction_2(last_one_week,prediction_time):\n",
        "  if prediction_time>0:\n",
        "    prediction=model_2.predict(scaler_2.transform(last_one_week))\n",
        "    next_last_week=np.concatenate((last_one_week,prediction), axis=1)\n",
        "    next_last_week=[np.delete(next_last_week,0)]\n",
        "    #print(next_last_week)\n",
        "    weather_prediction_2(next_last_week,prediction_time-1)\n",
        "  else:\n",
        "    print(last_one_week[0][-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6imeqEXIweKb",
        "outputId": "d511d72e-f8ee-4260-921f-e49f2a3d8fc4"
      },
      "source": [
        "# an example for 8th ov November\n",
        "weather_prediction_2([[2,6,1,8,2,-1,7]],1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.248996734619141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKbhAv2zwsQJ",
        "outputId": "041b7ed3-6f9d-46ea-f281-510d529eafbd"
      },
      "source": [
        "weather_prediction_2([[2,6,1,8,2,-1,7]],1)\n",
        "weather_prediction_1([[14,10,12,16,12,13,11]],1)\n",
        "#so for 8th of November:\n",
        "print('Expected average temperature for 8th of November:')\n",
        "np.mean([6.248996734619141,\n",
        "11.104191780090332])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6.248996734619141\n",
            "11.104191780090332\n",
            "Expected average temperature for 8th of November:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.676594257354736"
            ]
          },
          "metadata": {},
          "execution_count": 442
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZdOcgGuytNj",
        "outputId": "bf7b6f21-eb24-47cc-9bcf-f56f64abee47"
      },
      "source": [
        "weather_prediction_2([[2,6,1,8,2,-1,7]],8)\n",
        "weather_prediction_1([[14,10,12,16,12,13,11]],8)\n",
        "#so for 15th of November:\n",
        "print('Expected average temperature for 15th of November:')\n",
        "np.mean([4.641397476196289,\n",
        "9.447543144226074])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.641397476196289\n",
            "9.447543144226074\n",
            "Expected average temperature for 15th of November:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.044470310211182"
            ]
          },
          "metadata": {},
          "execution_count": 444
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InrfF9il1Buz",
        "outputId": "068bc583-25c4-4b75-b25b-fdbcef6e6872"
      },
      "source": [
        "weather_prediction_2([[2,6,1,8,2,-1,7]],29)\n",
        "weather_prediction_1([[14,10,12,16,12,13,11]],29)\n",
        "#so for 6th of December:\n",
        "print('Expected average temperature for 6th of December:')\n",
        "np.mean([2.4397642612457275,\n",
        "4.759843826293945])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4397642612457275\n",
            "4.759843826293945\n",
            "Expected average temperature for 6th of December:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.5998040437698364"
            ]
          },
          "metadata": {},
          "execution_count": 446
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDLDfyhu1QMf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}